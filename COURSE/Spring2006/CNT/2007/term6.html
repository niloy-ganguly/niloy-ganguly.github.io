




<div>

   <br> <br>
<p align="center"><font size="5" face="Times New Roman"><b>Edge weight 
revision for semantic net</b></font> <br> <br></p>

<p align="justify"><font size="3" face="Times New Roman"><i>Task 1:</i> 
Given an English corpus, build the co-occurrence network of words, i.e., 
two words is connected if they co-occur in a sentence. Call this network 
G_0 (semantic level 0).</font> <br></p>
<p align="justify"><font size="3" face="Times New Roman"><i>Task 2:</i> 
Mathematically derive an edge revision process that captures higher 
level semantic relationships between the words (G_i+1 = T(G_i)). This 
is something like the Google page ranking, but instead of nodes we revise 
the edges. </font> <br></p>
<p align="justify"><font size="3" face="Times New Roman"><i>Task 3: </i>
 Experimentations have to be done for checking the convergence etc.</font> <br>
</p>

<p align="justify"><font size="3" face="Times New Roman"><i>Task 4:</i> 
Clustering and some application of the graph for evaluation of the technique 
(we can choose any standard application like WSD or spellchecking or 
IR and use std. datasets and available packages for this part).</font> <br>
</p>
<ul>
<ul type="DISC">
  <li><font size="3" face="Times New Roman">Data Source – 
  Google</font></li>
  <li><font size="3" face="Times New Roman">References – Social 
  Network Analysis of Natural Language Text, Delip Rao &amp; Deepak Khemani, 
  ICON 2007. (other references will be provided by the contact persons).</font></li>
</ul>

</ul>
 <br>
<p><font size="3" face="Times New Roman">Contact Person - Mainly Monojit 
Choudhury and Prof. Shudeshna Sarkar.</font></p>


</div>

</div></body></html>
